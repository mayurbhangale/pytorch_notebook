{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "    1. Load Dataset\n",
    "    2. Make dataset Iterable\n",
    "    3. Create Model Class\n",
    "    4. Instantiate Model Class\n",
    "    5. Instantiate Loss Class\n",
    "    6. Instantiate Optimizer Class\n",
    "    7. Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./mnist',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " (0 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1490\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0275  0.6980\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.2235  0.9882\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.7765  0.9922\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.2980  0.9647  0.9882\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3333  0.9882  0.9020\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3333  0.9882  0.8745\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3333  0.9882  0.5686\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3373  0.9922  0.8824\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3333  0.9882  0.9765\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3333  0.9882  0.9882\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1098  0.7804  0.9882\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0980  0.5020\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " \n",
       " Columns 9 to 17 \n",
       "    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.2000  0.6235  0.9922\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.1882  0.9333  0.9882  0.9882\n",
       "   0.0000  0.0000  0.0000  0.0000  0.2118  0.8902  0.9922  0.9882  0.9373\n",
       "   0.0000  0.0000  0.0392  0.2353  0.8784  0.9882  0.9922  0.9882  0.7922\n",
       "   0.0000  0.0000  0.6392  0.9882  0.9882  0.9882  0.9922  0.9882  0.9882\n",
       "   0.0000  0.2000  0.9333  0.9922  0.9922  0.7451  0.4471  0.9922  0.8941\n",
       "   0.1882  0.9333  0.9882  0.9882  0.7020  0.0471  0.2941  0.4745  0.0824\n",
       "   0.6471  0.9922  0.9137  0.8157  0.3294  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9882  0.9412  0.2784  0.0745  0.1098  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9882  0.2471  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.7451  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.4392  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0980  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0275\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1882  0.6471\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.4471  0.9333  0.9922\n",
       "   0.5725  0.1882  0.1137  0.3333  0.6980  0.8824  0.9922  0.8745  0.6549\n",
       "   0.9882  0.8980  0.8431  0.9882  0.9882  0.9882  0.7686  0.5098  0.0000\n",
       "   0.9882  0.9922  0.9882  0.9882  0.9137  0.5686  0.0000  0.0000  0.0000\n",
       "   0.9882  0.9922  0.9882  0.5529  0.1451  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " \n",
       " Columns 18 to 26 \n",
       "    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.6235  0.1961  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9882  0.9294  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9137  0.9882  0.2235  0.0235  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.3294  0.9882  0.9922  0.4784  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.3765  0.7412  0.9922  0.6549  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.1843  0.3098  1.0000  0.6588  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.9922  0.9529  0.1961  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.9922  0.9882  0.6471  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.9922  0.9882  0.7647  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.9922  0.9882  0.7647  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  1.0000  0.9922  0.7686  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.9922  0.9882  0.5804  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0275  0.5294  0.9922  0.7294  0.0471  0.0000  0.0000  0.0000  0.0000\n",
       "   0.5137  0.9882  0.8824  0.2784  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9882  0.6784  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.6353  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.2196  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " \n",
       " Columns 27 to 27 \n",
       "    0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       " [torch.FloatTensor of size 1x28x28], 0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_img = train_dataset[0][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115fb6dd8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUIQfCIrwA0H9H4BpmwJXvvG+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115f02860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap ='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root='./mnist',\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_dataset))\n",
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iK8ANJEX4gKcIPJEX4gaQIP5DUXwFGhz+pWT5yuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115ed3c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap ='gray')\n",
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 .Make dataset Iterable\n",
    "- total = 60000\n",
    "- minibatch = 100 (num of eg in one iteration)\n",
    "- iterations: 3000\n",
    "- epoch\n",
    "    - epochs = iterations/ (total/minibatch)\n",
    "    -          3000/ (60000/10) = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create iterable object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check iterability\n",
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "### Iterate\n",
    "# example: whats iteration\n",
    "img_1 = np.ones((28, 28))\n",
    "img_2 = np.ones((28, 28))\n",
    "lst = [img_1, img_2]\n",
    "\n",
    "for i in lst:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        #here input_dim= x, output_dim= y\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiate model class\n",
    "- Input dimension:\n",
    "    - Size of image\n",
    "    - 28 x 28 = 784\n",
    "- Output Dimension: 10\n",
    "    - 0,1,2,3,4,5,6,7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of images\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instantiate Loss Class\n",
    "- Logistic Regression: Cross Entropy Loss\n",
    "    - Linear regression: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whats in nn.CrossEntropyLoss()\n",
    " - Automatically computers softmax(logistic/softmax function)\n",
    " - Computes cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Instantiate Optimizer Class \n",
    "- Simplified equation\n",
    "    - \\begin{equation*}\n",
    "       \\theta = \\theta - \\eta . \\nabla_\\theta\n",
    "       \\end{equation*}\n",
    "        - θ : parameters (our variables)\n",
    "        - η : Learning rate\n",
    "        - \\begin{align}\n",
    "        \\nabla_\\theta : \\text{Parameters gradients}\n",
    "          \\end{align}\n",
    "          \n",
    "- Even Simpler equation\n",
    "    - ``parameters = parameters - learning_rate * parameters_gradients``\n",
    "    - #### At every iteration, update model's parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.9133435487747192. Accuracy: 66.98\n",
      "Iteration: 1000. Loss: 1.6223598718643188. Accuracy: 75.52\n",
      "Iteration: 1500. Loss: 1.5008976459503174. Accuracy: 78.94\n",
      "Iteration: 2000. Loss: 1.2602624893188477. Accuracy: 80.64\n",
      "Iteration: 2500. Loss: 0.9759824872016907. Accuracy: 82.04\n",
      "Iteration: 3000. Loss: 1.1384949684143066. Accuracy: 82.92\n"
     ]
    }
   ],
   "source": [
    "iter = 0 \n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #Load images as Variable\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #Clear gradient wrt params\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward pass to get output\n",
    "        outputs = model(images)\n",
    "\n",
    "        #calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #Get gradients wrt params\n",
    "        loss.backward()\n",
    "\n",
    "        #update params\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            #calcuate accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            #iterate trough test dset\n",
    "            for images, labels in test_loader:\n",
    "                #load images to torch variable\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                #Forward pass only to get logits/outputs\n",
    "                outputs = model(images)\n",
    "                \n",
    "                #get predictions from max value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                #Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs\n",
      "Variable containing:\n",
      "-0.3867\n",
      "-1.2105\n",
      "-0.3524\n",
      "-0.2318\n",
      " 0.0445\n",
      "-0.5690\n",
      "-1.1736\n",
      " 2.7029\n",
      "-0.3069\n",
      " 0.7594\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('Outputs')\n",
    "        print(outputs[0, :])\n",
    "    _,predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('Prediction:')\n",
    "        print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "7\n",
      "Original Label:\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('Prediction:')\n",
    "        print(predicted[0])\n",
    "        \n",
    "        print('Original Label:')\n",
    "        print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.92\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _,predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    #Total number of labels\n",
    "    total += labels.size(0)\n",
    "    \n",
    "    #Total correct predictions\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "accuracy = 100 * (correct / total)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
